\documentclass[10pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{url}
\usepackage{titling}
\newlength{\bibitemsep}\setlength{\bibitemsep}{.2\baselineskip plus .05\baselineskip minus .05\baselineskip}
\newlength{\bibparskip}\setlength{\bibparskip}{0pt}
\let\oldthebibliography\thebibliography
\renewcommand\thebibliography[1]{%
  \oldthebibliography{#1}%
  \setlength{\parskip}{\bibitemsep}%
  \setlength{\itemsep}{\bibparskip}%
}



\setlength{\droptitle}{-1cm}
\usepackage[compact]{titlesec}
\titlespacing{\section}{0pt}{*0}{*0}
\titlespacing{\subsection}{0pt}{*0}{*0}
\titlespacing{\subsubsection}{0pt}{*0}{*0}


\title{Socio-technical Factors for Automated Test Generation \vspace{-2ex}}


\author{
  Iftekhar Ahmed\\
  University of California, Irvine\\
  \texttt{iftekha@uci.edu} \vspace{-5ex}
  \and
  Alex Groce\\
  Northern Arizona University\\
  \texttt{agroce@gmail.com}\vspace{-5ex}
}

\date{}

\begin{document}
\maketitle

\section{Proposal}

\subsection{Abstract}

This project proposes to investigate the applicability of \emph{socio-technical} factors as automated test generation heuristics. The  insight being, \emph{socio-technical} factors have proven to be effective in predicting failures, so such factors should also be effective in guided automated test case generation for both unbounded and limited time budget. In the first phase of this project, we will investigate the applicability of various \emph{socio-technical} factors: e.g., statements involved in merge conflicts, statements emitting specific bad code smells, parts of code that didn't go through proper review process as test generation heuristics. Such factors have not been used in automated test generation, although they have been proven to have significant impact on the bug proneness of code. In the second phase, we will compare the effectiveness of different \emph{socio-technical} factors along with traditionally used purely technical sourced code related factors as test case generation heuristics for limited time budget which is more suitable for incremental testing.

\subsection{Problem Statement}
Testing is an invaluable technique in ensuring that software is robust and reliable. However, there has been an exponential growth in the complexity of software and the cost of testing also has risen accordingly \cite{myers2011art}. We cannot exhaustively test these complex systems using manually written test cases, so one of the ways to ensure quality lies in improved automated test case generation \cite{anand2013orchestrated,harman2012search}. Various properties have been used for generating test cases, including
structural \cite{tonella2004evolutionary}, functional \cite{wegener2004evaluation} and non-functional properties \cite{wegener1998verifying}. The majority of these properties are technical in nature, however, software development is not a purely technical activity, it is a complex \emph{socio-technical} activity typically occurring concurrently and within the larger organizational goals and context. Development activity traces left behind in the code base, version control systems, issue trackers, and discussion forums allow us to understand these complex interactions. Researchers have recently started analyzing the complex interactions between \emph{socio-technical} factors for predicting failures. In our own work on identifying \emph{socio-technical} factors with fault prediction capability, we found that merge conflicts and design issues aka "code smells" are better predictors of bugginess of the lines of code \cite{ahmedempirical} when used together rather than being used individually. However, the applicability of these factors in automated test case generation is yet to be investigated. Intuitively such factors should be strong candidates for test case generation as they are highly associated with bugginess. Tests generated emphasizing on both traditional factors, such as cyclomatic complexity and \emph{socio-technical} factors, such as statements involved in merge conflict and having bad code smells, should be more effective in generating tests with higher defect identification capability compared to only using either of these categories separately.

%The primary idea behind this project is that \emph{socio-technical} factors have high association with fault proneness, so automated test cases generated using them , in conjunction with other traditional factors, should provide more effective test cases with  higher defect identification capability.

\subsection{Research Plan}

\noindent {\bf \emph{Socio-technical} factors for test case generation:} Previous work on generating test cases investigated structural \cite{tonella2004evolutionary}, functional \cite{wegener2004evaluation}, non-functional \cite{wegener1998verifying} properties. %\cite{oh2011transition}
None of these studies investigated the effectiveness of \emph{socio-technical} factors for test case generation. We propose to produce the first general, systematic examination of various \emph{socio-technical} factors for test case generation. We will start by using a large number of open source source projects collected from sources such as Github and after filtering for the mature open source projects, we will generate tests using state-of-the-art automated test generation systems. Then we will generate tests for the same projects using \emph{socio-technical} factors and compare their effectiveness in identifying real faults. We will use existing benchmarks such as Defects4J \cite{just2014defects4j}. As there are only 6 projects in the aforementioned benchmark, we will curate our own bug data-set combining information from  sources such as bug tracking systems and patches submitted to the code base for fixing bugs using the techniques used in our prior work \cite{ahmed2016can} and will release that as a benchmark. 
% identified using machine learning techniques \cite{ahmed2016can}. 
We will also use the existing manually written tests and augment them by generating additional tests using both state-of-the-art automated test generation systems and \emph{socio-technical} factors in conjunction and separately and compare their performance to identify the best set of factors.

\noindent {\bf \emph{Socio-technical} factors for \emph{limited-budget} test case generation:} In the second phase of the project, we will investigate the applicability of \emph{socio-technical} factors for generating test cases for limited time budget where the test case generation and execution time are only proportional to the \emph{size of change} instead of the \emph{whole code base}. Limited time budget test generation is more demanding then traditional testing because of the time constraint. Moreover, to be effective, limited-budget automated test generation should only require minimal additional computational effort compared to pure random testing which makes \emph{socio-technical} factors strong candidates for exploration as they do not require any complex infrastructure and calculating them adds minimum or no overhead. Similar to traditional automated test generation, the methods investigating the limited-budget testing \cite{groce2012lightweight} also focuses on using traditional technical factors. We propose to perform the first systematic investigation of effectiveness of different \emph{socio-technical} factors along with traditionally used purely technical factors as test case generation heuristics for limited time budget. As \emph{socio-technical} factors are strong predictors of bugginess, we hypothesize that \emph{socio-technical} factors in isolation or in combination with traditional factors are not only effective for traditional automated test case generation but also effective for limited time budget test generation. We will investigate the effectiveness for different time budgets using average percentage faults detected (APFD) \cite{elbaum2002test} of both known faults and seeded faults created using mutation testing technique \cite{ahmed2017applying}.

%Testing with a limited budget is critical as the entire process of downloading and building the code may be constrained to 50 minutes (for private repos) or 120 minutes (for public repos) \cite{TravisDoc}. 



%QuickCheck \cite{claessen2011quickcheck} and other property based testing tools \cite{papadakis2011proper} offer on the fly automatic testing using random testing \cite{bohme2014efficiency}. 
 

%However, testing methods that use coverage information, or even more expensive (and powerful) tools such as symbolic execution \cite{cadar2008klee} face an inherent limitation. For even a perfect method with capabilities for partitioning system behavior by faults, if the method has a cost (over that of random testing), it will be less effective than random testing, for some test budgets \cite{AutoEfficiency}. 

%Real-world techniques are not perfect in their defect targeting, and often impose considerable costs this is why performing symbolic execution only on seed tests, generated by some other method, is now a popular approach in both standard automated test generation and security-based fuzzing \cite{marinescu2012make}. 




\noindent{\bf Synergy:}  The proposed project fits well in the context our our group's ongoing work on using \emph{socio-technical} factors for fault prediction.

%\section{Data Policy}

%All analysis data from this project based on open source projects will be made public, along with analysis scripts, via GitHub or similar open source hosting solution.  Tools for mitigation will be hosted in the same way.  Depending on size of artifacts, only pointers to the actual repository artifact snapshots analyzed may be posted, rather than their full contents (since we expect to potentially analyze very large amounts of source code that is already accessible online).

\bibliographystyle{abbrv}
\bibliography{proposal}

\end{document}

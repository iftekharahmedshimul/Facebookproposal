\documentclass[10pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{url}
\usepackage{titling}
\newlength{\bibitemsep}\setlength{\bibitemsep}{.2\baselineskip plus .05\baselineskip minus .05\baselineskip}
\newlength{\bibparskip}\setlength{\bibparskip}{0pt}
\let\oldthebibliography\thebibliography
\renewcommand\thebibliography[1]{%
  \oldthebibliography{#1}%
  \setlength{\parskip}{\bibitemsep}%
  \setlength{\itemsep}{\bibparskip}%
}



\setlength{\droptitle}{-1cm}
\usepackage[compact]{titlesec}
\titlespacing{\section}{0pt}{*0}{*0}
\titlespacing{\subsection}{0pt}{*0}{*0}
\titlespacing{\subsubsection}{0pt}{*0}{*0}


\title{Socio-technical Factors for Automated Test Generation \vspace{-2ex}}


\author{
  Iftekhar Ahmed\\
  University of California, Irvine\\
  \texttt{iftekha@uci.edu} \vspace{-5ex}
  \and
  Alex Groce\\
  Northern Arizona University\\
  \texttt{agroce@gmail.com}\vspace{-5ex}
}

\date{}

\begin{document}
\maketitle

\section{Proposal}

\subsection{Abstract}

This project proposes to investigate the applicability of \emph{socio-technical} factors to automated test generation heuristics. The core insight is that \emph{socio-technical} factors have proven to be effective in predicting failures, so such factors should also be effective for guiding automated test case generation for both unbounded and limited time budgets. In the first phase of this project, we will investigate the applicability of various \emph{socio-technical} factors (e.g., statements involved in merge conflicts, statements emitting specific bad code smells, parts of code that didn't go through the proper review process) in test generation heuristics. Such factors have not been used in automated test generation, although they have been proven to have significant impact on the bug-proneness of code. In the second phase, we will compare the effectiveness of different \emph{socio-technical} factors (and traditionally-used purely technical source-code-related factors) in test case generation heuristics for the limited time budget test efforts essential for incremental testing.

\subsection{Problem Statement}
Testing is an essential technique for ensuring that software is robust and reliable. However, there has been an exponential growth in the complexity of software, and the cost of testing also has risen accordingly \cite{myers2011art}. We cannot effectively test such complex systems using manually written test cases: as a result quality assurance must increasingly rely on improved automated test case generation \cite{anand2013orchestrated,harman2012search}. Various code properties have been used for generating test cases, including
structural \cite{tonella2004evolutionary}, functional \cite{wegener2004evaluation}, and non-functional properties \cite{wegener1998verifying}. The majority of these properties are technical in nature:  rooted in the code itself or its specification; however, software development is not a purely technical activity, but a complex \emph{socio-technical} activity with larger organizational goals and context, and structure independent related to process, not product. Development activity traces left behind in the code base, version control systems, issue trackers, and discussion forums allow us to understand these complex interactions. Researchers have recently started analyzing the complex interactions between \emph{socio-technical} factors in order to predict which code is faulty. In our own work, we found that merge conflicts and design issues (a.k.a. "code smells") are better predictors of faulty code locations when used together rather than being used individually \cite{ahmedempirical} . However, the applicability of these factors in automated test case generation has yet to be investigated. Intuitively, such factors should be strong candidates for test case generation heuristics, since they can effectively predict faulty locations. Tests generated using both traditional factors (code complexity and size) and \emph{socio-technical} factors, such as statements involved in merge conflicts or with bad code smells, should be more effective, in that they include more context that influences code quality.

%The primary idea behind this project is that \emph{socio-technical} factors have high association with fault proneness, so automated test cases generated using them , in conjunction with other traditional factors, should provide more effective test cases with  higher defect identification capability.

\subsection{Research Plan}

\noindent {\bf \emph{Socio-technical} factors for test case generation:} Previous work on generating test cases investigated structural \cite{tonella2004evolutionary}, functional \cite{wegener2004evaluation}, and non-functional \cite{wegener1998verifying} properties. %\cite{oh2011transition}
None of these studies investigated the effectiveness of \emph{socio-technical} factors in test case generation. We propose to produce the first such general, systematic, examination. We will begin by comparing state-of-the-art test automated test generation systems, with and without use of socio-technical factors, on benchmarks such as Defects4J \cite{just2014defects4j}.  Because there are only 6 projects in the Defects4J benchmark, we will curate our own data-set combining information from  sources such as bug tracking systems and patches submitted to the code base for fixing bugs using the techniques used in our prior work \cite{ahmed2016can}, applied to a large number of randomly selected, mature open source projects, and will release that as a benchmark.  We will also use the existing manually written tests and augment them by generating additional tests using both state-of-the-art automated test generation systems and \emph{socio-technical} factors (in conjunction, and separately) and compare test performance to identify the best way to generate an effective, efficient test suite.

\noindent {\bf \emph{Socio-technical} factors for \emph{limited-budget} test case generation:} In the second phase of the project, we will investigate the applicability of \emph{socio-technical} factors for generating test cases for limited time budgets, where the test case generation and execution time are only proportional to the \emph{size of a change} instead of the \emph{whole code base}. Limited budget test generation is more demanding then traditional testing, in part because limited-budget automated test generation should only require minimal additional computational effort compared to pure random testing, if it is to obtain satisfactory results for very small budgets. Given these constraints, \emph{socio-technical} factors are strong candidates for exploration as they do not require any complex infrastructure and add minimal overhead to test generation.  As with traditional automated test generation, previous investigations of limited-budget test generation \cite{groce2012lightweight} have focused on using technical (code) factors only to guide testing. We propose to perform the first systematic investigation of \emph{socio-technical} factors in this context as well, using similar methods as with our first study.  
We will investigate the effectiveness for different time budgets using average percentage faults detected (APFD) \cite{elbaum2002test} curved for both known faults and seeded faults from mutation testing \cite{ahmed2017applying}.

%Testing with a limited budget is critical as the entire process of downloading and building the code may be constrained to 50 minutes (for private repos) or 120 minutes (for public repos) \cite{TravisDoc}. 



%QuickCheck \cite{claessen2011quickcheck} and other property based testing tools \cite{papadakis2011proper} offer on the fly automatic testing using random testing \cite{bohme2014efficiency}. 
 

%However, testing methods that use coverage information, or even more expensive (and powerful) tools such as symbolic execution \cite{cadar2008klee} face an inherent limitation. For even a perfect method with capabilities for partitioning system behavior by faults, if the method has a cost (over that of random testing), it will be less effective than random testing, for some test budgets \cite{AutoEfficiency}. 

%Real-world techniques are not perfect in their defect targeting, and often impose considerable costs this is why performing symbolic execution only on seed tests, generated by some other method, is now a popular approach in both standard automated test generation and security-based fuzzing \cite{marinescu2012make}. 




\noindent{\bf Synergy:}  The proposed project fits well in the context our our group's ongoing work on using \emph{socio-technical} factors for fault prediction.

%\section{Data Policy}

%All analysis data from this project based on open source projects will be made public, along with analysis scripts, via GitHub or similar open source hosting solution.  Tools for mitigation will be hosted in the same way.  Depending on size of artifacts, only pointers to the actual repository artifact snapshots analyzed may be posted, rather than their full contents (since we expect to potentially analyze very large amounts of source code that is already accessible online).

\bibliographystyle{abbrv}
\footnotesize{
    \bibliography{proposal}
}

\end{document}
